# Model Compression and Evaluationon on RHOAI

The compression and optimization of pretrained, off-the-shelf large language models (LLMs) is essential for organizations to reduce the hardware and energy requirements of their AI applications. This set of examples will introduce RHOAI users (ML Engineers and Data Scientists) to model compression using tools in the open-source VLLM project: [`llm-compressor`](https://github.com/vllm-project/llm-compressor) for model compression and the [`vllm`](https://github.com/vllm-project/vllm) deployment engine for performance benchmarking. Research in model compression is continually evolving and growing increasingly complex, but the examples require only a basic understanding of Python and the [HuggingFace software ecosystem](https://huggingface.co/docs/transformers/index).

> [!NOTE]  
> We also publish compressed versions of popular LLMs to HuggingFace that can be downloaded directly -- https://huggingface.co/RedHatAI

